{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import trange\n",
    "from gymnasium.utils.env_checker import check_env\n",
    "\n",
    "from flygym import Fly, Camera, SingleFlySimulation\n",
    "\n",
    "from flygym.examples.vision_connectome_model.arena import *\n",
    "from flygym.examples.vision_connectome_model.network import *\n",
    "from flygym.examples.vision_connectome_model.viz import *\n",
    "from flygym.examples.vision_connectome_model.controller import *\n",
    "\n",
    "#from flygym.mujoco import Parameters\n",
    "#from flygym.mujoco.arena import FlatTerrain\n",
    "#from flygym.mujoco.examples.obstacle_arena import ObstacleOdorArena\n",
    "#from flygym.mujoco.examples.turning_controller import HybridTurningNMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 4467/20000 [08:55<35:40,  7.26it/s]"
     ]
    }
   ],
   "source": [
    "#response_to_fly.py\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "from flygym import Fly, Camera\n",
    "from typing import Optional\n",
    "from dm_control.rl.control import PhysicsError\n",
    "\n",
    "from flygym.examples.vision_connectome_model import (\n",
    "    MovingFlyArena,\n",
    "    NMFRealisticVision,\n",
    "    visualize_vision,\n",
    ")\n",
    "from flygym.examples.head_stabilization import HeadStabilizationInferenceWrapper\n",
    "from flygym.examples.head_stabilization import get_head_stabilization_model_paths\n",
    "\n",
    "\n",
    "contact_sensor_placements = [\n",
    "    f\"{leg}{segment}\"\n",
    "    for leg in [\"LF\", \"LM\", \"LH\", \"RF\", \"RM\", \"RH\"]\n",
    "    for segment in [\"Tibia\", \"Tarsus1\", \"Tarsus2\", \"Tarsus3\", \"Tarsus4\", \"Tarsus5\"]\n",
    "]\n",
    "\n",
    "# fmt: off\n",
    "cells = [\n",
    "    \"T1\", \"T2\", \"T2a\", \"T3\", \"T4a\", \"T4b\", \"T4c\", \"T4d\", \"T5a\", \"T5b\", \"T5c\", \"T5d\",\n",
    "    \"Tm1\", \"Tm2\", \"Tm3\", \"Tm4\", \"Tm5Y\", \"Tm5a\", \"Tm5b\", \"Tm5c\", \"Tm9\", \"Tm16\", \"Tm20\",\n",
    "    \"Tm28\", \"Tm30\", \"TmY3\", \"TmY4\", \"TmY5a\", \"TmY9\", \"TmY10\", \"TmY13\", \"TmY14\", \"TmY15\",\n",
    "    \"TmY18\"\n",
    "]\n",
    "# fmt: on\n",
    "\n",
    "output_dir = Path(\"./outputs/connectome_constrained_vision/baseline_response/\")\n",
    "\n",
    "# If you trained the models yourself (by running ``collect_training_data.py``\n",
    "# followed by ``train_proprioception_model.py``), you can use the following\n",
    "# paths to load the models that you trained. Modify the paths if saved the\n",
    "# model checkpoints elsewhere.\n",
    "#stabilization_model_dir = Path(\"./outputs/head_stabilization/models/\")\n",
    "#stabilization_model_path = stabilization_model_dir / \"All.ckpt\"\n",
    "#scaler_param_path = stabilization_model_dir / \"joint_angle_scaler_params.pkl\"\n",
    "\n",
    "# Alternatively, you can use the pre-trained models that come with the\n",
    "# package. To do so, comment out the three lines above and uncomment the\n",
    "# following line.\n",
    "stabilization_model_path, scaler_param_path = get_head_stabilization_model_paths()\n",
    "\n",
    "\n",
    "def run_simulation(\n",
    "    arena: MovingFlyArena,\n",
    "    run_time: float = 1.0,\n",
    "    head_stabilization_model: Optional[HeadStabilizationInferenceWrapper] = None,\n",
    "):\n",
    "    fly = Fly(\n",
    "        contact_sensor_placements=contact_sensor_placements,\n",
    "        enable_adhesion=True,\n",
    "        enable_vision=True,\n",
    "        vision_refresh_rate=500,\n",
    "        neck_kp=1000,\n",
    "        head_stabilization_model=head_stabilization_model,\n",
    "    )\n",
    "\n",
    "    cam = Camera(\n",
    "        fly=fly,\n",
    "        camera_id=\"birdeye_cam\",\n",
    "        play_speed=0.2,\n",
    "        window_size=(800, 608),\n",
    "        fps=24,\n",
    "        play_speed_text=False,\n",
    "    )\n",
    "\n",
    "    sim = NMFRealisticVision(\n",
    "        fly=fly,\n",
    "        cameras=[cam],\n",
    "        arena=arena,\n",
    "    )\n",
    "\n",
    "    sim.reset(seed=0)\n",
    "    obs_hist = []\n",
    "    info_hist = []\n",
    "    rendered_image_snapshots = []\n",
    "    vision_observation_snapshots = []\n",
    "    nn_activities_snapshots = []\n",
    "\n",
    "    # Main simulation loop\n",
    "    for i in trange(int(run_time / sim.timestep)):\n",
    "        try:\n",
    "            obs, _, _, _, info = sim.step(action=np.array([1, 1]))\n",
    "        except PhysicsError:\n",
    "            print(\"Physics error, ending simulation early\")\n",
    "            break\n",
    "        obs_hist.append(obs)\n",
    "        info_hist.append(info)\n",
    "        rendered_img = sim.render()[0]\n",
    "        if rendered_img is not None:\n",
    "            rendered_image_snapshots.append(rendered_img)\n",
    "            vision_observation_snapshots.append(obs[\"vision\"])\n",
    "            nn_activities_snapshots.append(info[\"nn_activities\"])\n",
    "\n",
    "    return {\n",
    "        \"sim\": sim,\n",
    "        \"obs_hist\": obs_hist,\n",
    "        \"info_hist\": info_hist,\n",
    "        \"rendered_image_snapshots\": rendered_image_snapshots,\n",
    "        \"vision_observation_snapshots\": vision_observation_snapshots,\n",
    "        \"nn_activities_snapshots\": nn_activities_snapshots,\n",
    "    }\n",
    "\n",
    "\n",
    "def process_trial(terrain_type: str, stabilization_on: bool):\n",
    "    variation_name = f\"{terrain_type}terrain_stabilization{stabilization_on}\"\n",
    "\n",
    "    if terrain_type == \"flat\":\n",
    "        arena = MovingFlyArena(\n",
    "            move_speed=18, lateral_magnitude=1, terrain_type=terrain_type\n",
    "        )\n",
    "    elif terrain_type == \"blocks\":\n",
    "        arena = MovingFlyArena(\n",
    "            move_speed=13, lateral_magnitude=1, terrain_type=terrain_type\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid terrain type\")\n",
    "    if stabilization_on:\n",
    "        stabilization_model = HeadStabilizationInferenceWrapper(\n",
    "            model_path=stabilization_model_path,\n",
    "            scaler_param_path=scaler_param_path,\n",
    "        )\n",
    "    else:\n",
    "        stabilization_model = None\n",
    "\n",
    "    # Run simulation\n",
    "    res = run_simulation(\n",
    "        arena=arena, run_time=2.0, head_stabilization_model=stabilization_model\n",
    "    )\n",
    "\n",
    "    # Save visualization\n",
    "    visualize_vision(\n",
    "        Path(output_dir / f\"{variation_name}_vision_simulation.mp4\"),\n",
    "        res[\"sim\"].fly.retina,\n",
    "        res[\"sim\"].retina_mapper,\n",
    "        rendered_image_hist=res[\"rendered_image_snapshots\"],\n",
    "        vision_observation_hist=res[\"vision_observation_snapshots\"],\n",
    "        nn_activities_hist=res[\"nn_activities_snapshots\"],\n",
    "        fps=res[\"sim\"].cameras[0].fps,\n",
    "    )\n",
    "\n",
    "    # Save median and std of response for each cell\n",
    "    response_stats = {}\n",
    "    for cell in cells:\n",
    "        response_all = np.array(\n",
    "            [info[\"nn_activities\"][cell] for info in res[\"info_hist\"]]\n",
    "        )\n",
    "        response_mean = np.mean(response_all, axis=0)\n",
    "        response_std = np.std(response_all, axis=0)\n",
    "        response_stats[cell] = {\n",
    "            \"mean\": res[\"sim\"].retina_mapper.flyvis_to_flygym(response_mean),\n",
    "            \"std\": res[\"sim\"].retina_mapper.flyvis_to_flygym(response_std),\n",
    "        }\n",
    "    with open(output_dir / f\"{variation_name}_response_stats.pkl\", \"wb\") as f:\n",
    "        pickle.dump(response_stats, f)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from joblib import Parallel, delayed\n",
    "\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    configs = [\n",
    "        (terrain_type, stabilization_on)\n",
    "        for terrain_type in [\"flat\"]#, \"blocks\"]\n",
    "        for stabilization_on in [True]#, False]\n",
    "    ]\n",
    "\n",
    "    Parallel(n_jobs=-8)(delayed(process_trial)(*config) for config in configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#follow_fly_closed_loop.py\n",
    "import cv2\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n",
    "from typing import Optional\n",
    "from flygym import Fly, Camera\n",
    "from dm_control.rl.control import PhysicsError\n",
    "\n",
    "from flygym.examples.vision_connectome_model import (\n",
    "    MovingFlyArena,\n",
    "    NMFRealisticVision,\n",
    "    visualize_vision,\n",
    ")\n",
    "from flygym.examples.head_stabilization import HeadStabilizationInferenceWrapper\n",
    "from flygym.examples.head_stabilization import get_head_stabilization_model_paths\n",
    "\n",
    "\n",
    "contact_sensor_placements = [\n",
    "    f\"{leg}{segment}\"\n",
    "    for leg in [\"LF\", \"LM\", \"LH\", \"RF\", \"RM\", \"RH\"]\n",
    "    for segment in [\"Tibia\", \"Tarsus1\", \"Tarsus2\", \"Tarsus3\", \"Tarsus4\", \"Tarsus5\"]\n",
    "]\n",
    "\n",
    "# fmt: off\n",
    "cells = [\n",
    "    \"T1\", \"T2\", \"T2a\", \"T3\", \"T4a\", \"T4b\", \"T4c\", \"T4d\", \"T5a\", \"T5b\", \"T5c\", \"T5d\",\n",
    "    \"Tm1\", \"Tm2\", \"Tm3\", \"Tm4\", \"Tm5Y\", \"Tm5a\", \"Tm5b\", \"Tm5c\", \"Tm9\", \"Tm16\", \"Tm20\",\n",
    "    \"Tm28\", \"Tm30\", \"TmY3\", \"TmY4\", \"TmY5a\", \"TmY9\", \"TmY10\", \"TmY13\", \"TmY14\", \"TmY15\",\n",
    "    \"TmY18\"\n",
    "]\n",
    "# fmt: on\n",
    "\n",
    "baseline_dir = Path(\"./outputs/connectome_constrained_vision/baseline_response/\")\n",
    "output_dir = Path(\"./outputs/connectome_constrained_vision/closed_loop_control/\")\n",
    "\n",
    "# If you trained the models yourself (by running ``collect_training_data.py``\n",
    "# followed by ``train_proprioception_model.py``), you can use the following\n",
    "# paths to load the models that you trained. Modify the paths if saved the\n",
    "# model checkpoints elsewhere.\n",
    "#stabilization_model_dir = Path(\"./outputs/head_stabilization/models/\")\n",
    "#stabilization_model_path = stabilization_model_dir / \"All.ckpt\"\n",
    "#scaler_param_path = stabilization_model_dir / \"joint_angle_scaler_params.pkl\"\n",
    "\n",
    "# Alternatively, you can use the pre-trained models that come with the\n",
    "# package. To do so, comment out the three lines above and uncomment the\n",
    "# following line.\n",
    "stabilization_model_path, scaler_param_path = get_head_stabilization_model_paths()\n",
    "\n",
    "\n",
    "def run_simulation(\n",
    "    arena: MovingFlyArena,\n",
    "    cell: str,\n",
    "    run_time: float,\n",
    "    response_mean: np.ndarray,\n",
    "    response_std: np.ndarray,\n",
    "    z_score_threshold: float,\n",
    "    tracking_gain: float,\n",
    "    head_stabilization_model: Optional[HeadStabilizationInferenceWrapper] = None,\n",
    "):\n",
    "    # Setup NMF simulation\n",
    "    fly = Fly(\n",
    "        contact_sensor_placements=contact_sensor_placements,\n",
    "        enable_adhesion=True,\n",
    "        enable_vision=True,\n",
    "        vision_refresh_rate=500,\n",
    "        neck_kp=500,\n",
    "        head_stabilization_model=head_stabilization_model,\n",
    "    )\n",
    "    cam = Camera(\n",
    "        fly=fly,\n",
    "        camera_id=\"birdeye_cam\",\n",
    "        play_speed=0.2,\n",
    "        window_size=(800, 608),\n",
    "        fps=24,\n",
    "        play_speed_text=False,\n",
    "    )\n",
    "    sim = NMFRealisticVision(fly=fly, cameras=[cam], arena=arena)\n",
    "\n",
    "    # Calculate center-of-mass of each ommatidium\n",
    "    ommatidia_coms = np.empty((fly.retina.num_ommatidia_per_eye, 2))\n",
    "    for i in range(fly.retina.num_ommatidia_per_eye):\n",
    "        mask = fly.retina.ommatidia_id_map == i + 1\n",
    "        ommatidia_coms[i, :] = np.argwhere(mask).mean(axis=0)\n",
    "\n",
    "    # Run simulation\n",
    "    obs, info = sim.reset(seed=0)\n",
    "    obs_hist = []\n",
    "    info_hist = []\n",
    "    rendered_image_snapshots = []\n",
    "    vision_observation_snapshots = []\n",
    "    nn_activities_snapshots = []\n",
    "\n",
    "    dn_drive = np.array([1, 1])\n",
    "    for i in trange(int(run_time / sim.timestep)):\n",
    "        if info[\"vision_updated\"]:\n",
    "            # Estimate object mask\n",
    "            nn_activities = info[\"nn_activities\"]\n",
    "            t3_activities = sim.retina_mapper.flyvis_to_flygym(nn_activities[cell])\n",
    "            t3_zscore = (t3_activities - response_mean) / response_std\n",
    "            obj_mask = t3_zscore < z_score_threshold\n",
    "            _mask_viz = fly.retina.hex_pxls_to_human_readable(obj_mask[1])\n",
    "            cv2.imwrite(f\"temp/{i}.jpg\", _mask_viz.astype(np.uint8) * 255)\n",
    "\n",
    "            # Calculate turning bias based on object mask\n",
    "            size_per_eye = obj_mask.sum(axis=1)\n",
    "            com_per_eye = np.full((2, 2), np.nan)\n",
    "            for eye_idx in range(2):\n",
    "                if size_per_eye[eye_idx] > 0:\n",
    "                    masked_xy_coords = ommatidia_coms[obj_mask[eye_idx], :]\n",
    "                    com_per_eye[eye_idx, :] = masked_xy_coords.mean(axis=0)\n",
    "            com_per_eye /= np.array([fly.retina.nrows, fly.retina.ncols])\n",
    "            size_per_eye = size_per_eye / fly.retina.num_ommatidia_per_eye\n",
    "            center_deviation = com_per_eye[:, 1].copy()\n",
    "            center_deviation[0] = 1 - center_deviation[0]\n",
    "            _center_deviation = center_deviation.copy()\n",
    "            _center_deviation[size_per_eye == 0] = 1e9  # make sure it will break\n",
    "            if size_per_eye.sum() == 0:\n",
    "                turning_bias = 0\n",
    "            else:\n",
    "                turning_bias = (\n",
    "                    -size_per_eye[0] * _center_deviation[0]\n",
    "                    + size_per_eye[1] * _center_deviation[1]\n",
    "                ) / size_per_eye.sum()\n",
    "\n",
    "            # Calculate DN drive based on turning bias\n",
    "            dn_inner = max(0.4, 1 - np.abs(turning_bias * tracking_gain) * 0.6)\n",
    "            dn_outer = min(1.2, 1 + np.abs(turning_bias * tracking_gain) * 0.2)\n",
    "            if turning_bias < 0:\n",
    "                dn_drive = np.array([dn_inner, dn_outer])\n",
    "            else:\n",
    "                dn_drive = np.array([dn_outer, dn_inner])\n",
    "\n",
    "        try:\n",
    "            obs, _, _, _, info = sim.step(action=dn_drive)\n",
    "        except PhysicsError:\n",
    "            print(\"Physics error, breaking simulation\")\n",
    "            break\n",
    "        rendered_img = sim.render()[0]\n",
    "        info[\"com_per_eye\"] = com_per_eye\n",
    "        info[\"size_per_eye\"] = size_per_eye\n",
    "        info[\"center_deviation\"] = center_deviation\n",
    "        info[\"turning_bias\"] = turning_bias\n",
    "        obs_hist.append(obs)\n",
    "        info_hist.append(info)\n",
    "        if rendered_img is not None:\n",
    "            rendered_image_snapshots.append(rendered_img)\n",
    "            vision_observation_snapshots.append(obs[\"vision\"])\n",
    "            nn_activities_snapshots.append(info[\"nn_activities\"])\n",
    "\n",
    "    return {\n",
    "        \"sim\": sim,\n",
    "        \"obs_hist\": obs_hist,\n",
    "        \"info_hist\": info_hist,\n",
    "        \"rendered_image_snapshots\": rendered_image_snapshots,\n",
    "        \"vision_observation_snapshots\": vision_observation_snapshots,\n",
    "        \"nn_activities_snapshots\": nn_activities_snapshots,\n",
    "    }\n",
    "\n",
    "\n",
    "def process_trial(terrain_type: str, stabilization_on: bool):\n",
    "    variation_name = f\"{terrain_type}terrain_stabilization{stabilization_on}\"\n",
    "\n",
    "    with open(baseline_dir / f\"{variation_name}_response_stats.pkl\", \"rb\") as f:\n",
    "        response_stats = pickle.load(f)\n",
    "\n",
    "    if terrain_type == \"flat\":\n",
    "        arena = MovingFlyArena(\n",
    "            move_speed=16, lateral_magnitude=1, terrain_type=terrain_type\n",
    "        )\n",
    "    elif terrain_type == \"blocks\":\n",
    "        arena = MovingFlyArena(\n",
    "            move_speed=13, lateral_magnitude=1, terrain_type=terrain_type\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Invalid terrain type\")\n",
    "    if stabilization_on:\n",
    "        stabilization_model = HeadStabilizationInferenceWrapper(\n",
    "            model_path=stabilization_model_path,\n",
    "            scaler_param_path=scaler_param_path,\n",
    "        )\n",
    "    else:\n",
    "        stabilization_model = None\n",
    "\n",
    "    # Run simulation\n",
    "    res = run_simulation(\n",
    "        arena=arena,\n",
    "        cell=\"T3\",\n",
    "        run_time=2.0,\n",
    "        response_mean=response_stats[\"T3\"][\"mean\"],\n",
    "        response_std=response_stats[\"T3\"][\"std\"],\n",
    "        z_score_threshold=-4,\n",
    "        tracking_gain=4,\n",
    "        head_stabilization_model=stabilization_model,\n",
    "    )\n",
    "\n",
    "    # Save visualization\n",
    "    visualize_vision(\n",
    "        Path(output_dir / f\"{variation_name}_vision_simulation.mp4\"),\n",
    "        res[\"sim\"].fly.retina,\n",
    "        res[\"sim\"].retina_mapper,\n",
    "        rendered_image_hist=res[\"rendered_image_snapshots\"],\n",
    "        vision_observation_hist=res[\"vision_observation_snapshots\"],\n",
    "        nn_activities_hist=res[\"nn_activities_snapshots\"],\n",
    "        fps=res[\"sim\"].cameras[0].fps,\n",
    "    )\n",
    "\n",
    "    # Save sim data for diagnostics\n",
    "    try:\n",
    "        with open(output_dir / f\"{variation_name}_sim_data.pkl\", \"wb\") as f:\n",
    "            # Remove sim, and remove LayerResponse from info_hist. They\n",
    "            # work poorly with pickle\n",
    "            del res[\"sim\"]\n",
    "            for info in res[\"info_hist\"]:\n",
    "                del info[\"nn_activities\"]\n",
    "            pickle.dump(res, f)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save sim data for {variation_name}: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from joblib import Parallel, delayed\n",
    "\n",
    "    output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    configs = [\n",
    "        (terrain_type, stabilization_on)\n",
    "        for terrain_type in [\"flat\"]#, \"blocks\"]\n",
    "        for stabilization_on in [True]#, False]\n",
    "    ]\n",
    "\n",
    "    Parallel(n_jobs=-8)(delayed(process_trial)(*config) for config in configs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flygym0.2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
